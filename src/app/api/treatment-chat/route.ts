import { NextResponse } from 'next/server';

interface Message {
  role: 'system' | 'user' | 'assistant';
  content: string;
}

export async function POST(request: Request): Promise<NextResponse> {
  try {
    console.log('üì• Recibiendo solicitud POST');
    const { messages }: { messages: Message[] } = await request.json();
    console.log('üìù Mensajes recibidos:', messages);

    
    const systemPrompt: Message = {
      role: 'system',
      content: `
        Eres un asistente m√©dico virtual cuyo prop√≥sito principal es ayudar a evaluar los s√≠ntomas de los pacientes y ofrecer recomendaciones claras.
        Realiza preguntas directas para obtener los datos m√°s relevantes sobre los s√≠ntomas del paciente, y evita distracciones.
        Despu√©s de 2-3 preguntas clave, proporciona una recomendaci√≥n sobre qu√© hacer a continuaci√≥n, como consultar a un m√©dico, hacer un seguimiento o esperar.
        No es necesario calcular o reportar probabilidades, solo sugerir acciones con base en las respuestas.

        Tu lenguaje debe ser profesional, emp√°tico y claro, y siempre debes aclarar que no sustituyes una consulta m√©dica presencial.
      `,
    };
  
    if (!messages.some(msg => msg.role === 'system')) {
      messages.unshift(systemPrompt);
    }

    const apiKey = process.env.GROQ_API_KEY;

    if (!apiKey) {
      console.error('‚ùå GROQ_API_KEY no est√° configurada');
      return NextResponse.json({
        error: 'Falta la clave de API',
        details: 'Por favor, define GROQ_API_KEY en tu archivo .env.local',
      }, { status: 500 });
    }

    const models = [
      'llama3-70b-8192',
      'mixtral-8x7b-32768',
      'llama2-70b-4096',
    ];
    

    for (const model of models) {
      try {
        console.log(`ü§ñ Intentando modelo: ${model}`);

        const groqResponse = await fetch('https://api.groq.com/openai/v1/chat/completions', {

          method: 'POST',
          headers: {
            'Content-Type': 'application/json',
            'Authorization': `Bearer ${apiKey}`,
          },
          body: JSON.stringify({
            model,
            messages,
            temperature: 0.7,
            max_tokens: 2000,
            stream: false,
          }),
        });

        console.log(`üîÅ Status respuesta: ${groqResponse.status}`);

        if (!groqResponse.ok) {
          const errorData = await groqResponse.json().catch(() => null);
          console.warn('‚ö†Ô∏è Fallo en modelo:', model, errorData);

          // Contin√∫a con el siguiente modelo si este falla
          continue;
        }

        const apiResponse = await groqResponse.json();
        const content = apiResponse?.choices?.[0]?.message?.content;

        if (!content) {
          console.error('‚ùå Respuesta sin contenido v√°lido');
          return NextResponse.json({
            error: 'Respuesta de la API sin contenido',
            details: 'La respuesta no contiene contenido v√°lido'
          }, { status: 500 });
        }

        console.log('‚úÖ Respuesta exitosa:', content);

        // Devolver la respuesta completa con los mensajes
        return NextResponse.json({
          success: true,
          content: content,
          messages: [...messages, { role: 'assistant', content: content }],
          model: model,
          timestamp: new Date().toISOString()
        });

      } catch (modelError) {
        console.error(`‚ö†Ô∏è Error con modelo ${model}:`, modelError);
        continue; // Intenta con el siguiente modelo
      }
    }

    // Si ninguno de los modelos funcion√≥
    return NextResponse.json({
      error: 'Todos los modelos fallaron',
      details: 'Intenta nuevamente m√°s tarde',
    }, { status: 500 });

  } catch (error) {
    console.error('üí• Error general del servidor:', error);
    return NextResponse.json({
      error: 'Error interno del servidor',
      details: error instanceof Error ? error.message : String(error),
    }, { status: 500 });
  }
}
